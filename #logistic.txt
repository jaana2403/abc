#logistic
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def logistic_regression(X, y, num_iterations=5000, learning_rate=0.1):
    weights = np.zeros(X.shape[1])
    for _ in range(num_iterations):
        h = sigmoid(np.dot(X, weights))
        weights -= learning_rate * np.dot(X.T, (h - y)) / y.size
    return weights

# Load dataset
iris = load_iris()
X, y = iris.data[:, :2], (iris.target != 0).astype(int)

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize features
scaler = StandardScaler()
X_train_std, X_test_std = scaler.fit_transform(X_train), scaler.transform(X_test)

# Train logistic regression model
weights = logistic_regression(X_train_std, y_train)

# Make predictions and calculate accuracy
y_pred = sigmoid(np.dot(X_test_std, weights)) > 0.5
print(f'Accuracy: {np.mean(y_pred == y_test):.4f}')

# Plot decision boundary
x_min, x_max = X_train_std[:, 0].min() - 1, X_train_std[:, 0].max() + 1
y_min, y_max = X_train_std[:, 1].min() - 1, X_train_std[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),
                     np.arange(y_min, y_max, 0.1))

Z = sigmoid(np.dot(np.c_[xx.ravel(), yy.ravel()], weights)) > 0.5
Z = Z.reshape(xx.shape)

plt.contourf(xx, yy, Z, alpha=0.4)
plt.scatter(X_train_std[:, 0], X_train_std[:, 1], c=y_train, edgecolors='k')
plt.xlabel('Sepal length')
plt.ylabel('Sepal width')
plt.title('Logistic Regression Decision Boundary')
plt.savefig('plot.png')
